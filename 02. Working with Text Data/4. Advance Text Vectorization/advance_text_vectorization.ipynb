{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0a730a-2cc5-4292-924c-50ef49c29faa",
   "metadata": {},
   "source": [
    "# **Advance Text Representation Techniques - Word2Vec, Pretrained GloVe and Pretrained BERT**\n",
    "\n",
    "### **What's Covered?**\n",
    "1. Text Vectorization\n",
    "2. Various Text Representation Techniques\n",
    "    - Basic Vectorization Approaches\n",
    "    - Distributed Representation\n",
    "    - Contextual Language Representation\n",
    "3. Latent Space\n",
    "4. Word Embedding\n",
    "5. Implementing Word2Vec\n",
    "\n",
    "### **Text Representation (Vectorization)**\n",
    "Text vectorization is a way to represent words or phrases as vectors in a high-dimensional space based on their contextual meaning within a corpus of text data. \n",
    "\n",
    "**The idea is that if two phrases are similar then the vectors that represent those phrases should be close together and vice versa.**\n",
    "\n",
    "1. Feature Extraction is an important step for any machine learning problem.\n",
    "2. No matter how good a modeling algorithm you use, if you feed in poor features, you will get poor results.\n",
    "3. **Remember:** \"Garbage in, garbage out.\"\n",
    "4. Data can be text, images, videos, or speech.\n",
    "5. Mathematically representing images, videos and speech is straightforward.\n",
    "6. However, feature representation for text is often much more involved as compared to other formats of data.\n",
    "\n",
    "### **Various Feature Representation Techniques**\n",
    "\n",
    "1. Basic Vectorization Approaches (Eg: BoW and TF IDF)\n",
    "2. Distributed Representation (Eg: Word2Vec, GloVe, FastText)\n",
    "3. Universal Language Representation (Eg: GPT, BERT, etc...)\n",
    "\n",
    "#### **a. Basic Vectorization Approaches**\n",
    "- Eg: One-Hot Encoding, Bag of Words, Bag of N-Grams, and TFIDF\n",
    "- **Drawbacks:** They are discrete representations, vector representation is sparse and high-dimensional, and they cannot handle OOV words.\n",
    "\n",
    "#### **b. Distributed Representation**\n",
    "- Eg: Word Embeddings (Word2Vec, GloVe, fastText), Document Embeddings (Doc2Vec)\n",
    "- Text embeddings are a way to represent words or phrases as vectors in a high-dimensional space based on their semantic meaning within a corpus of text data. The idea is that if two phrases are similar then the vectors that represent those phrases should be close together and vice versa.\n",
    "- Word2Vec don't have a good way of handling OOV words\n",
    "- **Handling OOV words Problem:** One way is by modifying the training process by bringing in characters and other sub-level linguistic components such as morphological properties (e.g., prefixes, suffixes, word endings, etc...). **FastText** from facebook follows this approach.\n",
    "- **Drawbacks:** Above techniques only provide word embeddings. Inorder to get document embedding, we can aggregate the word embeddings to get document embeddings. But, for sentences \"dog bites man\" and \"man bites dog\", both will receive same representation.\n",
    "\n",
    "#### **c. Universal Language Representation**\n",
    "- Problem in the above approach: One word gets one fixed representation. Eg: \"I went to bank to withdraw money\" and \"I sat on the river bank\" both uses the word \"bank\"\n",
    "- Examples of Universal Language Representation: GPT, BERT, etc... \n",
    "- **Key Idea:** Learn embedding on a generic task like **Language Modeling** on a massive corpus and then fine-tune learnings on a task-specific data. This is also known as **transfer learning**.\n",
    "\n",
    "### **Latent Space**\n",
    "A latent space, also known as a latent feature space or embedding space, is an embedding of a set of items within a manifold in which items which resemble each other more closely are positioned closer to one another in the latent space.\n",
    "\n",
    "### **Word Embedding**\n",
    "In natural language processing (NLP), [word embedding](https://en.wikipedia.org/wiki/Word_embedding) is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning. Word embeddings can be obtained using a set of [language modeling](https://en.wikipedia.org/wiki/Language_model) and [feature learning](https://en.wikipedia.org/wiki/Feature_learning) techniques where words or phrases from the vocabulary are mapped to vectors of real numbers.\n",
    "\n",
    "Methods to generate this mapping include **neural networks**, **dimensionality reduction on the word co-occurrence matrix**, **probabilistic models**, **explainable knowledge base method**, and **explicit representation in terms of the context in which words appear**.\n",
    "\n",
    "Traditionally, one of the main **limitations of word embeddings** (word vector space models in general) is that words with multiple meanings are conflated into a single representation (a single vector in the semantic space). In other words, [polysemy](https://en.wikipedia.org/wiki/Polysemy) and [homonymy](https://en.wikipedia.org/wiki/Homonym) are not handled properly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ef419-bcfe-4048-a516-2b6eec31a7cc",
   "metadata": {},
   "source": [
    "## **Word2Vec: Word Embedding**\n",
    "\"You shall know the word by the company it keeps.\" by JR Firth\n",
    "\n",
    "**Distributional Semantics (i.e. a word is characterized by the company it keeps)**  \n",
    "W2v works well because there is an idea of meaning distribution in the context.\n",
    "\n",
    "**Algorithms to generate Word2Vec Embeddings**\n",
    "1. SkipGram\n",
    "2. Continuous Bag of Words\n",
    "\n",
    "**Issue**  \n",
    "Even if the word is having three different meaning, W2v will return the weighted average of all three as the output. Now the question is, \n",
    "- Is it possible to segregate the three vectors to represent the words based in the context? \n",
    "$$ OR $$\n",
    "- Is it possible to disambiguate the word vectors based on the context?\n",
    "\n",
    "Word2Vec is not capturing the contextual information. This is where BERT comes handy. (BERT is discussed at the end)\n",
    "\n",
    "### **Introducing `gensim`**\n",
    "\n",
    "Run the following to install and upgrade `gensim`:\n",
    "```python\n",
    "! pip install gensim  \n",
    "! pip install --upgrade gensim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25241fcc-dacc-4340-aa66-33944867383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa36816-b9f3-4dd2-bd42-3b1de9f772ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.2\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584268e0-8ece-47f6-b7f6-57927aa6d183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of times.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE age of foolishness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text\n",
       "0     it Was the best oF Times $\n",
       "1     It was The worst of times.\n",
       "2     IT 9 was tHe age Of wisdom\n",
       "3  it was thE age of foolishness"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "lst_text = ['it Was the best oF Times $', \n",
    "            'It was The worst of times.',\n",
    "            'IT 9 was tHe age Of wisdom', \n",
    "            'it was thE age of foolishness']\n",
    "\n",
    "df = pd.DataFrame({'text': lst_text})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3c301e-cd2a-403d-ba56-bc16a066529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean(doc): \n",
    "    # doc is a string of text\n",
    "    \n",
    "    # Let's define a regex to match special characters and digits\n",
    "    regex = \"[^a-zA-Z]\"\n",
    "    doc = re.sub(regex, \" \", doc)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    doc = doc.lower()\n",
    "        \n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "    # Stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Join and return\n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f4b408-c79d-4e95-b2d0-6bce49a49bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "      <td>best time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of times.</td>\n",
       "      <td>worst time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "      <td>age wisdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE age of foolishness</td>\n",
       "      <td>age foolishness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text       clean_text\n",
       "0     it Was the best oF Times $        best time\n",
       "1     It was The worst of times.       worst time\n",
       "2     IT 9 was tHe age Of wisdom       age wisdom\n",
       "3  it was thE age of foolishness  age foolishness"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['text'].apply(lambda x : clean(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b83865c-ce67-42b4-86ad-71feba36a9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "      <td>best time</td>\n",
       "      <td>[best, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of times.</td>\n",
       "      <td>worst time</td>\n",
       "      <td>[worst, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>[age, wisdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE age of foolishness</td>\n",
       "      <td>age foolishness</td>\n",
       "      <td>[age, foolishness]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text       clean_text tokenised_sentences\n",
       "0     it Was the best oF Times $        best time        [best, time]\n",
       "1     It was The worst of times.       worst time       [worst, time]\n",
       "2     IT 9 was tHe age Of wisdom       age wisdom       [age, wisdom]\n",
       "3  it was thE age of foolishness  age foolishness  [age, foolishness]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenised_sentences'] = df['clean_text'].apply(lambda doc : doc.split())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7dd1021-1f7c-426a-af81-6c33ba278b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_vect = Word2Vec(df['tokenised_sentences'], vector_size=100, min_count=1)\n",
    "\n",
    "print(word2vec_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5a048d-f5c5-4368-bbfd-3210b440b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents used for Training: 4\n",
      "\n",
      "Vocabulary size: 6\n",
      "\n",
      "Vocabulary: ['age', 'time', 'foolishness', 'wisdom', 'worst', 'best']\n",
      "\n",
      "Let's look at the vocabulary stored in the object: {'age': 0, 'time': 1, 'foolishness': 2, 'wisdom': 3, 'worst': 4, 'best': 5}\n",
      "\n",
      "Vector Size: 100\n"
     ]
    }
   ],
   "source": [
    "# We can check out what is learned by \"word2vec_vect\"\n",
    "\n",
    "print(f\"Number of documents used for Training: {word2vec_vect.corpus_count}\")\n",
    "print()\n",
    "print(f\"Vocabulary size: {len(word2vec_vect.wv.index_to_key)}\")\n",
    "print()\n",
    "print(f\"Vocabulary: {word2vec_vect.wv.index_to_key}\")\n",
    "print()\n",
    "print(f\"Let's look at the vocabulary stored in the object: {word2vec_vect.wv.key_to_index}\")\n",
    "print()\n",
    "print(f\"Vector Size: {word2vec_vect.vector_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019f1f54-bee8-484b-aa9b-a5a95526871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequencies: [('age', 2), ('time', 2), ('foolishness', 1), ('wisdom', 1), ('worst', 1), ('best', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Word frequencies\n",
    "word_frequencies = {word: word2vec_vect.wv.get_vecattr(word, \"count\") for word in word2vec_vect.wv.index_to_key}\n",
    "\n",
    "print(f\"Word frequencies: {list(word_frequencies.items())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e4af12-a61e-4556-b1e8-3fa81fa5ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding Shape: (100,)\n",
      "\n",
      "[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
     ]
    }
   ],
   "source": [
    "# Getting vector for a word\n",
    "\n",
    "print(f\"Word Embedding Shape: { word2vec_vect.wv['time'].shape }\")\n",
    "print()\n",
    "print(word2vec_vect.wv[\"time\"])\n",
    "\n",
    "# # We can also use the following:\n",
    "# print(word2vec_vect.wv.__getitem__('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81abaf61-f749-41ba-8aff-f711588ce2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6, 100)\n",
      "\n",
      "[[-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
      "  -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
      "  -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
      "  -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
      "   2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
      "   7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
      "   6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
      "  -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
      "   9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
      "   8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
      "  -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
      "  -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
      "   4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
      "  -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
      "   4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
      "  -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
      "  -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
      "  -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
      "  -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
      "   7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
      "  -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
      "  -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
      "  -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
      "   3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
      "  -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
      " [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "   7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      "  -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      "  -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "   6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "   2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "   6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      "  -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      "  -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "   6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "   7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      "  -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "   1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      "  -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "   9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      "  -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "   3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "   7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "   5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      "  -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      "  -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "   1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "   2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "   2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "   5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
      " [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
      "   7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
      "  -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
      "   9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
      "   5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
      "  -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
      "   7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
      "  -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
      "  -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
      "  -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
      "  -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
      "   3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
      "  -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
      "  -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
      "  -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
      "   4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
      "  -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
      "  -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
      "   4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
      "   9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
      "   1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
      "   1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
      "   8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
      "   9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
      "   5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
      " [-8.2426779e-03  9.2993546e-03 -1.9766092e-04 -1.9672764e-03\n",
      "   4.6036304e-03 -4.0953159e-03  2.7431143e-03  6.9399667e-03\n",
      "   6.0654259e-03 -7.5107943e-03  9.3823504e-03  4.6718083e-03\n",
      "   3.9661205e-03 -6.2435055e-03  8.4599797e-03 -2.1501649e-03\n",
      "   8.8251876e-03 -5.3620026e-03 -8.1294188e-03  6.8245591e-03\n",
      "   1.6711927e-03 -2.1985089e-03  9.5136007e-03  9.4938548e-03\n",
      "  -9.7740470e-03  2.5052286e-03  6.1566923e-03  3.8724565e-03\n",
      "   2.0227872e-03  4.3050171e-04  6.7363144e-04 -3.8206363e-03\n",
      "  -7.1402504e-03 -2.0888723e-03  3.9238976e-03  8.8186832e-03\n",
      "   9.2591504e-03 -5.9759365e-03 -9.4026709e-03  9.7643770e-03\n",
      "   3.4297847e-03  5.1661171e-03  6.2823449e-03 -2.8042626e-03\n",
      "   7.3227035e-03  2.8302716e-03  2.8710044e-03 -2.3803699e-03\n",
      "  -3.1282497e-03 -2.3701417e-03  4.2764368e-03  7.6057913e-05\n",
      "  -9.5842788e-03 -9.6655441e-03 -6.1481940e-03 -1.2856961e-04\n",
      "   1.9974159e-03  9.4319675e-03  5.5843508e-03 -4.2906962e-03\n",
      "   2.7831673e-04  4.9643586e-03  7.6983096e-03 -1.1442233e-03\n",
      "   4.3234206e-03 -5.8143795e-03 -8.0419064e-04  8.1000505e-03\n",
      "  -2.3600650e-03 -9.6634552e-03  5.7792603e-03 -3.9298222e-03\n",
      "  -1.2228728e-03  9.9805174e-03 -2.2563506e-03 -4.7570644e-03\n",
      "  -5.3293873e-03  6.9808899e-03 -5.7088719e-03  2.1136629e-03\n",
      "  -5.2556600e-03  6.1207139e-03  4.3573068e-03  2.6063549e-03\n",
      "  -1.4910829e-03 -2.7460635e-03  8.9929365e-03  5.2157748e-03\n",
      "  -2.1625196e-03 -9.4703101e-03 -7.4260519e-03 -1.0637414e-03\n",
      "  -7.9494715e-04 -2.5629092e-03  9.6827205e-03 -4.5852066e-04\n",
      "   5.8737611e-03 -7.4475873e-03 -2.5060738e-03 -5.5498634e-03]\n",
      " [-7.1390150e-03  1.2410306e-03 -7.1767163e-03 -2.2446180e-03\n",
      "   3.7193035e-03  5.8331238e-03  1.1981833e-03  2.1027315e-03\n",
      "  -4.1103913e-03  7.2253332e-03 -6.3070417e-03  4.6472158e-03\n",
      "  -8.2199732e-03  2.0364679e-03 -4.9770521e-03 -4.2476882e-03\n",
      "  -3.1089843e-03  5.6552086e-03  5.7984008e-03 -4.9746488e-03\n",
      "   7.7333092e-04 -8.4957778e-03  7.8098057e-03  9.2572914e-03\n",
      "  -2.7423275e-03  8.0022332e-04  7.4665190e-04  5.4778848e-03\n",
      "  -8.6060790e-03  5.8445573e-04  6.8694223e-03  2.2315944e-03\n",
      "   1.1246764e-03 -9.3221553e-03  8.4823668e-03 -6.2641273e-03\n",
      "  -2.9923737e-03  3.4937870e-03 -7.7262759e-04  1.4112913e-03\n",
      "   1.7819917e-03 -6.8288995e-03 -9.7248117e-03  9.0405848e-03\n",
      "   6.1980546e-03 -6.9129276e-03  3.4034825e-03  2.0606398e-04\n",
      "   4.7537456e-03 -7.1199429e-03  4.0269541e-03  4.3474343e-03\n",
      "   9.9573694e-03 -4.4737398e-03 -1.3892639e-03 -7.3173214e-03\n",
      "  -9.6978294e-03 -9.0802573e-03 -1.0227549e-03 -6.5032900e-03\n",
      "   4.8497282e-03 -6.1640264e-03  2.5191857e-03  7.3944090e-04\n",
      "  -3.3921539e-03 -9.7922329e-04  9.9791251e-03  9.1458866e-03\n",
      "  -4.4618296e-03  9.0830270e-03 -5.6417631e-03  5.9309220e-03\n",
      "  -3.0972182e-03  3.4317516e-03  3.0172265e-03  6.9004609e-03\n",
      "  -2.3738837e-03  8.7750368e-03  7.5894282e-03 -9.5476462e-03\n",
      "  -8.0082091e-03 -7.6378966e-03  2.9232574e-03 -2.7947223e-03\n",
      "  -6.9295205e-03 -8.1282640e-03  8.3091799e-03  1.9904887e-03\n",
      "  -9.3280170e-03 -4.7927164e-03  3.1367384e-03 -4.7132061e-03\n",
      "   5.2808430e-03 -4.2334413e-03  2.6417959e-03 -8.0456873e-03\n",
      "   6.2098862e-03  4.8188888e-03  7.8719261e-04  3.0134476e-03]\n",
      " [-8.7274825e-03  2.1301615e-03 -8.7354420e-04 -9.3190884e-03\n",
      "  -9.4281426e-03 -1.4107180e-03  4.4324086e-03  3.7040710e-03\n",
      "  -6.4986930e-03 -6.8730675e-03 -4.9994122e-03 -2.2868442e-03\n",
      "  -7.2502876e-03 -9.6033178e-03 -2.7436293e-03 -8.3628409e-03\n",
      "  -6.0388758e-03 -5.6709289e-03 -2.3441375e-03 -1.7069972e-03\n",
      "  -8.9569986e-03 -7.3519943e-04  8.1525063e-03  7.6904297e-03\n",
      "  -7.2061159e-03 -3.6668312e-03  3.1185520e-03 -9.5707225e-03\n",
      "   1.4764392e-03  6.5244664e-03  5.7464195e-03 -8.7630618e-03\n",
      "  -4.5171441e-03 -8.1401607e-03  4.5956374e-05  9.2636338e-03\n",
      "   5.9733056e-03  5.0673080e-03  5.0610625e-03 -3.2429171e-03\n",
      "   9.5521836e-03 -7.3564244e-03 -7.2703874e-03 -2.2653891e-03\n",
      "  -7.7856064e-04 -3.2161034e-03 -5.9258583e-04  7.4888230e-03\n",
      "  -6.9751858e-04 -1.6249407e-03  2.7443992e-03 -8.3591007e-03\n",
      "   7.8558037e-03  8.5361041e-03 -9.5840869e-03  2.4462664e-03\n",
      "   9.9049713e-03 -7.6658037e-03 -6.9669187e-03 -7.7365171e-03\n",
      "   8.3959233e-03 -6.8133592e-04  9.1444086e-03 -8.1582209e-03\n",
      "   3.7430846e-03  2.6350426e-03  7.4271322e-04  2.3276759e-03\n",
      "  -7.4690939e-03 -9.3583735e-03  2.3545765e-03  6.1484552e-03\n",
      "   7.9856887e-03  5.7358947e-03 -7.7733636e-04  8.3061643e-03\n",
      "  -9.3363142e-03  3.4061326e-03  2.6675343e-04  3.8572443e-03\n",
      "   7.3857834e-03 -6.7251669e-03  5.5844807e-03 -9.5222248e-03\n",
      "  -8.0445886e-04 -8.6887367e-03 -5.0986730e-03  9.2892265e-03\n",
      "  -1.8582619e-03  2.9144264e-03  9.0712793e-03  8.9381328e-03\n",
      "  -8.2084350e-03 -3.0123137e-03  9.8866057e-03  5.1044310e-03\n",
      "  -1.5880871e-03 -8.6920215e-03  2.9615164e-03 -6.6758976e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Access the 100D vectors for all 7 words\n",
    "\n",
    "print(f\"Shape: { word2vec_vect.wv[word2vec_vect.wv.index_to_key].shape }\")\n",
    "print()\n",
    "print(word2vec_vect.wv[word2vec_vect.wv.index_to_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60557cf-6395-4b08-8068-f5146efb4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# word2vec_vect.save('model/first_word_vectors.bin')\n",
    "\n",
    "# # load model\n",
    "# word2vec_vect = Word2Vec.load('model/first_word_vectors.bin')\n",
    "# print(word2vec_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a83e4af-d4ee-4174-90ac-98b888d18db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of word embeddings\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = word2vec_vect.wv[word2vec_vect.wv.index_to_key]\n",
    "pca = PCA(n_components = 2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "# create a scatter plot of the projection\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(word2vec_vect.wv.index_to_key)\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b63dffee-45b5-45b2-9709-c10a9589fe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wisdom', 0.06797593832015991)]\n"
     ]
    }
   ],
   "source": [
    "# Find most similar words\n",
    "similar_words = word2vec_vect.wv.most_similar('time', topn=1)\n",
    "\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1125b825-788c-4783-baae-7c7c459fcfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13887982"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the similarity between word vectors\n",
    "\n",
    "word2vec_vect.wv.similarity('best', 'worst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc7e54-fb96-4118-86b3-898c36c51ae4",
   "metadata": {},
   "source": [
    "### **Getting Sentence Embedding (Document Embeddings)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d70b5584-a418-460d-b784-1748f7d0118a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best', 'time']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove out-of-vocabulary words\n",
    "\n",
    "sentence = ['best', 'bansal', 'time', 'kanav']\n",
    "\n",
    "vocab_tokens = [word for word in sentence if word in word2vec_vect.wv.index_to_key]\n",
    "\n",
    "vocab_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed7f90d3-9971-4823-9c33-16b33db38357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.6735850e-03,  2.8979499e-03,  2.1581696e-03, -1.7885750e-03,\n",
       "       -9.8061212e-04, -3.7891967e-03,  2.7690111e-03,  4.8756767e-03,\n",
       "       -4.6693720e-03, -6.5232953e-03, -2.7048176e-03, -5.3278962e-03,\n",
       "       -6.4251497e-03, -1.2493895e-03,  3.0445517e-04, -5.6858570e-04,\n",
       "        3.8068579e-04,  9.2990650e-04, -3.0666459e-03, -1.1344015e-03,\n",
       "       -3.3043111e-03, -2.6271159e-03,  8.2706194e-03, -1.0838672e-03,\n",
       "       -2.2073742e-04, -3.7620717e-04, -9.0713974e-04, -2.5862674e-03,\n",
       "       -1.3156777e-04,  6.6179251e-03,  7.8556351e-03, -6.5627526e-03,\n",
       "       -2.5582409e-03, -6.9178990e-03,  1.9483893e-03,  6.0251304e-03,\n",
       "        6.4321910e-03,  5.5842018e-03,  7.2997799e-03,  3.0152500e-03,\n",
       "        8.7251253e-03, -7.1729645e-03, -8.2131261e-03, -1.3105709e-03,\n",
       "       -1.9392008e-03,  2.3391065e-03,  2.6729943e-03,  2.9715800e-03,\n",
       "        4.0672242e-04,  8.2550046e-05,  5.2809850e-03, -8.9346431e-03,\n",
       "        3.8251362e-03,  6.0026506e-03, -5.2615297e-03,  5.4140193e-03,\n",
       "        9.4578769e-03, -5.6464854e-04, -3.8392697e-03, -1.3056444e-05,\n",
       "       -6.9205649e-05,  1.2628853e-03,  2.2532057e-03, -6.6235880e-03,\n",
       "        3.6663515e-03,  4.0026912e-03,  4.2561139e-03, -1.7194152e-03,\n",
       "       -1.7866492e-05, -1.3664386e-03, -6.7761191e-04, -1.2985931e-03,\n",
       "        6.7115780e-03,  6.1228252e-03, -7.8244333e-04,  7.9815416e-04,\n",
       "       -8.2111200e-03,  4.5453617e-04,  2.7050036e-03,  9.6003409e-05,\n",
       "       -9.9213817e-04, -1.4492136e-03,  5.2344799e-03, -7.9753939e-03,\n",
       "        2.0204962e-04, -5.3818068e-03, -2.5371348e-03, -2.9714126e-04,\n",
       "        4.1687128e-04, -9.1784005e-04,  5.0794631e-03,  3.6809542e-03,\n",
       "       -3.0058809e-03, -5.4469449e-03,  3.5847109e-03,  3.8838149e-03,\n",
       "        1.8792974e-03, -5.5417679e-03, -3.2742890e-03, -1.0850094e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create document vectors by averaging word vectors\n",
    "np.mean(word2vec_vect.wv[vocab_tokens], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dead67e-1d14-4392-ad1b-243c375836e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vector(doc, model):\n",
    "    \"\"\"Remove out-of-vocabulary words. \n",
    "    Create document vectors by averaging word vectors.\"\"\"\n",
    "    tokens = [word for word in doc if word in model]\n",
    "    if tokens:\n",
    "        doc_embedding = np.mean(model[tokens], axis=0)\n",
    "    else:\n",
    "        doc_embedding = np.zeros(model.vector_size)\n",
    "    return doc_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91159d06-e813-4a58-8be3-284e8246121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>w2v_doc_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "      <td>best time</td>\n",
       "      <td>[best, time]</td>\n",
       "      <td>[-0.008673585, 0.00289795, 0.0021581696, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of times.</td>\n",
       "      <td>worst time</td>\n",
       "      <td>[worst, time]</td>\n",
       "      <td>[-0.007879351, 0.0024533845, -0.0009934164, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>[age, wisdom]</td>\n",
       "      <td>[-0.0043894527, 0.004767893, 0.0024528443, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE age of foolishness</td>\n",
       "      <td>age foolishness</td>\n",
       "      <td>[age, foolishness]</td>\n",
       "      <td>[-0.00022083164, 0.0016568756, -0.0008546477, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text       clean_text tokenised_sentences  \\\n",
       "0     it Was the best oF Times $        best time        [best, time]   \n",
       "1     It was The worst of times.       worst time       [worst, time]   \n",
       "2     IT 9 was tHe age Of wisdom       age wisdom       [age, wisdom]   \n",
       "3  it was thE age of foolishness  age foolishness  [age, foolishness]   \n",
       "\n",
       "                                  w2v_doc_embeddings  \n",
       "0  [-0.008673585, 0.00289795, 0.0021581696, -0.00...  \n",
       "1  [-0.007879351, 0.0024533845, -0.0009934164, 0....  \n",
       "2  [-0.0043894527, 0.004767893, 0.0024528443, 0.0...  \n",
       "3  [-0.00022083164, 0.0016568756, -0.0008546477, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['w2v_doc_embeddings'] = df[\"tokenised_sentences\"].apply(lambda doc : get_document_vector(doc, word2vec_vect.wv))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeffa4e0-9247-4213-b839-9eb868710032",
   "metadata": {},
   "source": [
    "## **Pretrained Word2Vec and GloVe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e01acb4-ebdc-445f-91b4-d6c8d9032cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbe8e63f-adf7-4f8d-b6eb-d5e87e2d2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the sake of this example, we will be loading pre-trained GloVe model\n",
    "# # You can also choose a Word2Vec or a FastText model as well\n",
    "# # Reference: https://github.com/piskvorky/gensim-data\n",
    "\n",
    "# glove_vect = api.load('glove-twitter-50')\n",
    "\n",
    "# # Approax 200MB Size\n",
    "# # Save Embeddings\n",
    "# glove_vect.save('pretrained_models/.50d_glove_vec.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1f5455f-384b-4da0-95bb-666eb65ec5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n"
     ]
    }
   ],
   "source": [
    "# Load Embeddings\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_vect = KeyedVectors.load('pretrained_models/.50d_glove_vec.kv')\n",
    "\n",
    "print(type(glove_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f36fcebd-4c12-4531-a133-a38deedb1c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1193514\n",
      "Vector Size: 50\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary Size and Word Embedding Shape\n",
    "\n",
    "print(f\"Vocabulary size: {len(glove_vect.index_to_key)}\")\n",
    "print(f\"Vector Size: {glove_vect.vector_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ce374d5-9aaa-4b68-8716-de4d6043d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding Shape: (50,)\n",
      "\n",
      "[ 1.7885   -0.067292  0.46616  -0.81783   0.10752   0.30621   1.4632\n",
      " -0.12453  -0.10154  -0.23087  -0.572     0.086826 -4.051     0.85883\n",
      "  0.71311  -0.049015 -0.51012   0.22284  -0.98466   0.78809   0.53688\n",
      "  0.17593   0.26659  -0.86271   0.051508  0.29894   0.74473  -0.85046\n",
      " -0.32939  -0.31356   0.63817  -1.1198   -0.1482   -0.46216   0.046157\n",
      " -0.46282  -0.32383   1.5272    0.76098  -0.1311   -0.35028   0.51516\n",
      " -0.07257   0.2536    0.5363   -0.46969   0.3285    0.17779  -0.47109\n",
      "  0.37841 ]\n"
     ]
    }
   ],
   "source": [
    "# Getting vector for a word\n",
    "\n",
    "print(f\"Word Embedding Shape: { glove_vect['college'].shape }\")\n",
    "print()\n",
    "print(glove_vect['college'])\n",
    "\n",
    "# # We can also use the following:\n",
    "# print(model.wv.__getitem__('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dc32cdf-5467-438f-ad4a-2b7a0d01b481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'time', 'foolishness', 'wisdom', 'worst', 'best']\n"
     ]
    }
   ],
   "source": [
    "tokens = word2vec_vect.wv.index_to_key\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "634ca59a-26b6-42d9-bd93-4cca780a8ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = glove_vect[tokens]\n",
    "pca = PCA(n_components = 2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "# create a scatter plot of the projection\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "for i, word in enumerate(tokens):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf0cc7c0-6175-4f6b-872b-e19fb1ab3671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('then', 0.9046667814254761), ('break', 0.9012036323547363), ('last', 0.8918827176094055), ('maybe', 0.8871403336524963), ('before', 0.884469747543335)]\n"
     ]
    }
   ],
   "source": [
    "# Find most similar words\n",
    "similar_words = glove_vect.most_similar('time', topn=5)\n",
    "\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85300fc3-7d34-4259-ab5d-a6d64d643cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sharepoint', 0.8866323828697205),\n",
       " ('administrator', 0.8673086166381836),\n",
       " ('programmer', 0.8619340658187866),\n",
       " ('architect', 0.8591458201408386),\n",
       " ('oracle', 0.8557209372520447)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vect.most_similar(\"developer\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f619fcc-876b-4211-85ba-25962f44f048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7817412"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the similarity between word vectors\n",
    "\n",
    "glove_vect.similarity(\"developer\", \"development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75966b83-adb4-4178-832f-33a024c0291c",
   "metadata": {},
   "source": [
    "### **Getting Sentence Embedding from Pretrained Model (Document Embeddings)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6f8063b-c90e-4954-ba97-3a75e113be81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>w2v_doc_embeddings</th>\n",
       "      <th>glove_doc_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "      <td>best time</td>\n",
       "      <td>[best, time]</td>\n",
       "      <td>[-0.008673585, 0.00289795, 0.0021581696, -0.00...</td>\n",
       "      <td>[0.432825, 0.1588, 0.39231, -0.493835, 0.00431...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of times.</td>\n",
       "      <td>worst time</td>\n",
       "      <td>[worst, time]</td>\n",
       "      <td>[-0.007879351, 0.0024533845, -0.0009934164, 0....</td>\n",
       "      <td>[0.73222, 0.23221499, 0.29085773, -0.31792, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>[age, wisdom]</td>\n",
       "      <td>[-0.0043894527, 0.004767893, 0.0024528443, 0.0...</td>\n",
       "      <td>[-0.045359, -0.66945, -0.33981, 0.167995, 0.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE age of foolishness</td>\n",
       "      <td>age foolishness</td>\n",
       "      <td>[age, foolishness]</td>\n",
       "      <td>[-0.00022083164, 0.0016568756, -0.0008546477, ...</td>\n",
       "      <td>[0.14098799, 0.16774501, -0.592085, 0.2619315,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text       clean_text tokenised_sentences  \\\n",
       "0     it Was the best oF Times $        best time        [best, time]   \n",
       "1     It was The worst of times.       worst time       [worst, time]   \n",
       "2     IT 9 was tHe age Of wisdom       age wisdom       [age, wisdom]   \n",
       "3  it was thE age of foolishness  age foolishness  [age, foolishness]   \n",
       "\n",
       "                                  w2v_doc_embeddings  \\\n",
       "0  [-0.008673585, 0.00289795, 0.0021581696, -0.00...   \n",
       "1  [-0.007879351, 0.0024533845, -0.0009934164, 0....   \n",
       "2  [-0.0043894527, 0.004767893, 0.0024528443, 0.0...   \n",
       "3  [-0.00022083164, 0.0016568756, -0.0008546477, ...   \n",
       "\n",
       "                                glove_doc_embeddings  \n",
       "0  [0.432825, 0.1588, 0.39231, -0.493835, 0.00431...  \n",
       "1  [0.73222, 0.23221499, 0.29085773, -0.31792, -0...  \n",
       "2  [-0.045359, -0.66945, -0.33981, 0.167995, 0.70...  \n",
       "3  [0.14098799, 0.16774501, -0.592085, 0.2619315,...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['glove_doc_embeddings'] = df[\"tokenised_sentences\"].apply(lambda doc : get_document_vector(doc, glove_vect))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef693a4-7560-45fc-b255-90e6f8394785",
   "metadata": {},
   "source": [
    "## **Word2Vec vs BERT**\n",
    "\n",
    "**Embeddings**  \n",
    "Word2Vec offers pre-trained word embeddings that anyone can use off-the-shelf. The embeddings are key: value pairs, essentially 1-1 mappings between words and their respective vectors. Word2Vec takes a single word as input and outputs a single vector representation of that word. \n",
    "\n",
    "Since BERT generates contextual embeddings, it takes as input a sequence (usually a sentence) rather than a single word. BERT needs to be shown the context that surrounding words provide before it can generate a word embedding. With BERT, you do need to have the actual model as the vector representations of words will vary based on the specific sequences you’re inputting. The output is a fixed-length vector representation of the input sentence. \n",
    "\n",
    "BERT or Bidirectional Encoder Representations from Transformers, is a technique that allows for bidirectional training of Transformers for natural language modeling tasks. Language models which are bidirectionally trained can learn deeper context from language than single-direction models. BERT generates context aware embeddings that allow for multiple representations (each representation, in this case, is a vector) of each word based on a given word’s context.\n",
    "\n",
    "**Word Ordering**  \n",
    "Word2Vec embeddings do not take into account the word position.\n",
    "\n",
    "BERT model explicitly takes as input the position (index) of each word in the sentence before calculating its embedding.\n",
    "\n",
    "**Out-of-Vocabulary**  \n",
    "Since Word2Vec learns embeddings at word level, it can only generate embeddings for words that existed in it’s training set (aka it’s “vocabulary space”). This is a major drawback to Word2Vec - that it just doesn’t support Out-of-Vocabulary words.\n",
    "\n",
    "Alternatively, BERT learns representations at the subword level, so a BERT model will have a smaller vocabulary space than the number of unique words in its training corpus. In turn, BERT is able to generate embeddings for words outside of its vocabulary space giving it a near infinite vocabulary. \n",
    "\n",
    "## **Sentence BERT (SBERT)**\n",
    "\n",
    "```python\n",
    "!pip install -U sentence-transformers\n",
    "```\n",
    "\n",
    "Sentence BERT References:  \n",
    "https://www.sbert.net/index.html  \n",
    "https://www.sbert.net/docs/pretrained_models.html  \n",
    "\n",
    "Find the paper for Sentence BERT here: https://arxiv.org/pdf/1908.10084.pdf\n",
    "\n",
    "**BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.**\n",
    "\n",
    "**Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT.**\n",
    "\n",
    "### Usage\n",
    "\n",
    "- Computing Sentence Embeddings\n",
    "- Semantic Textual Similarity\n",
    "- Semantic Search\n",
    "- Retrieve and Re-Rank\n",
    "- Clustering\n",
    "- Paraphrase Mining\n",
    "- Translated Sentence Mining\n",
    "- Cross Encoders\n",
    "- Image Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3ab07ac-ae79-4969-9e70-da4bc6607766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06fd0489-ba5b-40e6-a860-6eb77db69b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "bert_vect = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf87d5-bf4a-43d4-9473-9d606c808d03",
   "metadata": {},
   "source": [
    "### Model Overview\n",
    "\n",
    "```\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('model_name')\n",
    "```\n",
    "\n",
    "All models are hosted on the [HuggingFace Model Hub](https://huggingface.co/sentence-transformers).\n",
    "\n",
    "The following table provides an overview of (selected) models. They have been extensively evaluated for their quality to embedded sentences (Performance Sentence Embeddings) and to embedded search queries & paragraphs (Performance Semantic Search).\n",
    "\n",
    "The **all-* models** where trained on all available training data (more than 1 billion training pairs) and are designed as general purpose models. The **all-mpnet-base-v2** model provides the best quality, while **all-MiniLM-L6-v2 is 5 times faster** and still offers good quality. Toggle All models to see all evaluated models or visit [HuggingFace Model Hub](https://huggingface.co/models?library=sentence-transformers) to view all existing sentence-transformers models.\n",
    "\n",
    "#### Model Name  \n",
    "**`all-mpnet-base-v2`**\n",
    "> Description: \tAll-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs.  \n",
    "> Dimensions: \t768  \n",
    "> Suitable Score Functions: \tdot-product (util.dot_score), cosine-similarity (util.cos_sim), euclidean distance  \n",
    "> Size: \t420 MB  \n",
    "> Training Data: \t1B+ training pairs. For details, see model card.  \n",
    "> Model Card: \thttps://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "**`multi-qa-mpnet-base-dot-v1`**\n",
    "> Description: \tThis model was tuned for semantic search: Given a query/question, if can find relevant passages. It was trained on a large and diverse set of (question, answer) pairs.  \n",
    "> Dimensions: \t768  \n",
    "> Suitable Score Functions: \tdot-product (util.dot_score)  \n",
    "> Size: \t420 MB  \n",
    "> Training Data: \t215M (question, answer) pairs from diverse sources.  \n",
    "> Model Card: \thttps://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
    "\n",
    "**`all-distilroberta-v1`**\n",
    "> Description: \tAll-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs.  \n",
    "> Dimensions:\t768  \n",
    "> Suitable Score Functions:\tdot-product (util.dot_score), cosine-similarity (util.cos_sim), euclidean distance  \n",
    "> Size:\t290 MB  \n",
    "> Training Data:\t1B+ training pairs. For details, see model card.  \n",
    "> Model Card: \thttps://huggingface.co/sentence-transformers/all-distilroberta-v1\n",
    "\n",
    "**`all-MiniLM-L6-v2`**\n",
    "> Description: \tAll-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs.  \n",
    "> Dimensions: \t384  \n",
    "> Suitable Score Functions: \tdot-product (util.dot_score), cosine-similarity (util.cos_sim), euclidean distance  \n",
    "> Size: \t80 MB  \n",
    "> Training Data: \t1B+ training pairs. For details, see model card.  \n",
    "> Model Card: \thttps://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "\n",
    "**List of Pretrained models available:**\n",
    "```\n",
    "all-MiniLM-L12-v2\n",
    "multi-qa-distilbert-cos-v1\n",
    "multi-qa-MiniLM-L6-cos-v1\n",
    "multi-qa-MiniLM-L6-cos-v1\n",
    "paraphrase-multilingual-mpnet-base-v2\n",
    "paraphrase-albert-small-v2\n",
    "paraphrase-multilingual-MiniLM-L12-v2\n",
    "paraphrase-MiniLM-L3-v2\n",
    "distiluse-base-multilingual-cased-v1\n",
    "distiluse-base-multilingual-cased-v2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a829e960-f028-4487-a11a-5c14eeb980f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This framework generates embeddings for each input sentence\n",
      "Embedding: [-1.37173459e-02 -4.28515188e-02 -1.56286024e-02  1.40537797e-02\n",
      "  3.95537801e-02  1.21796258e-01  2.94333864e-02 -3.17523889e-02\n",
      "  3.54959629e-02 -7.93139860e-02  1.75878592e-02 -4.04370055e-02\n",
      "  4.97259274e-02  2.54912041e-02 -7.18700588e-02  8.14968869e-02\n",
      "  1.47070049e-03  4.79627140e-02 -4.50336300e-02 -9.92174819e-02\n",
      " -2.81769671e-02  6.45046532e-02  4.44670469e-02 -4.76217121e-02\n",
      " -3.52952629e-02  4.38671932e-02 -5.28565831e-02  4.33033478e-04\n",
      "  1.01921469e-01  1.64072085e-02  3.26996446e-02 -3.45986821e-02\n",
      "  1.21339206e-02  7.94871151e-02  4.58346587e-03  1.57778263e-02\n",
      " -9.68205091e-03  2.87625752e-02 -5.05806208e-02 -1.55793773e-02\n",
      " -2.87906546e-02 -9.62282810e-03  3.15556638e-02  2.27348655e-02\n",
      "  8.71449336e-02 -3.85027416e-02 -8.84718597e-02 -8.75498541e-03\n",
      " -2.12342888e-02  2.08923370e-02 -9.02077407e-02 -5.25732227e-02\n",
      " -1.05638960e-02  2.88310722e-02 -1.61454901e-02  6.17840327e-03\n",
      " -1.23234391e-02 -1.07336827e-02  2.83353832e-02 -5.28567657e-02\n",
      " -3.58618200e-02 -5.97988926e-02 -1.09055676e-02  2.91566290e-02\n",
      "  7.97979161e-02 -3.27878020e-04  6.83502015e-03  1.32718394e-02\n",
      " -4.24619988e-02  1.87657140e-02 -9.89234447e-02  2.09050011e-02\n",
      " -8.69605765e-02 -1.50151905e-02 -4.86201942e-02  8.04414526e-02\n",
      " -3.67700611e-03 -6.65044561e-02  1.14556782e-01 -3.04228738e-02\n",
      "  2.96631698e-02 -2.80695632e-02  4.64989990e-02 -2.25513615e-02\n",
      "  8.54222924e-02  3.15446667e-02  7.34541789e-02 -2.21861992e-02\n",
      " -5.29678278e-02  1.27129918e-02 -5.27340025e-02 -1.06188737e-01\n",
      "  7.04731718e-02  2.76736487e-02 -8.05531889e-02  2.39649769e-02\n",
      " -2.65125111e-02 -2.17331015e-02  4.35275808e-02  4.84712198e-02\n",
      " -2.37067416e-02  2.85768267e-02  1.11846179e-01 -6.34935796e-02\n",
      " -1.58318412e-02 -2.26169564e-02 -1.31027699e-02 -1.62065646e-03\n",
      " -3.60928848e-02 -9.78297070e-02 -4.67729010e-02  1.76271480e-02\n",
      " -3.97491977e-02 -1.76419970e-04  3.39627787e-02 -2.09633652e-02\n",
      "  6.33661682e-03 -2.59410944e-02  8.10410082e-02  6.14393204e-02\n",
      " -5.44597022e-03  6.48275912e-02 -1.16844065e-01  2.36861259e-02\n",
      " -1.32058384e-02 -1.12476498e-01  1.90049261e-02 -1.74661930e-34\n",
      "  5.58949709e-02  1.94244403e-02  4.65438738e-02  5.18645681e-02\n",
      "  3.89390662e-02  3.40541340e-02 -4.32114154e-02  7.90636837e-02\n",
      " -9.79530215e-02 -1.27441054e-02 -2.91870739e-02  1.02052009e-02\n",
      "  1.88115723e-02  1.08942531e-01  6.63465261e-02 -5.35295047e-02\n",
      " -3.29228491e-02  4.69827168e-02  2.28882991e-02  2.74114795e-02\n",
      " -2.91982964e-02  3.12706754e-02 -2.22850423e-02 -1.02282181e-01\n",
      " -2.79116649e-02  1.13792913e-02  9.06308815e-02 -4.75414693e-02\n",
      " -1.00718960e-01 -1.23232054e-02 -7.96928704e-02 -1.44636221e-02\n",
      " -7.76400715e-02 -7.66919181e-03  9.73955169e-03  2.24204734e-02\n",
      "  7.77268186e-02 -3.17157316e-03  2.11537480e-02 -3.30393650e-02\n",
      "  9.55244340e-03 -3.73011529e-02  2.61360500e-02 -9.79085639e-03\n",
      " -6.31505251e-02  5.77436946e-03 -3.80030796e-02  1.29684769e-02\n",
      " -1.82499643e-02 -1.56283174e-02 -1.23362232e-03  5.55579104e-02\n",
      "  1.13092436e-04 -5.61256371e-02  7.40165412e-02  1.84452068e-02\n",
      " -2.66368482e-02  1.31951645e-02  7.50086680e-02 -2.46797018e-02\n",
      " -3.24005559e-02 -1.57675166e-02 -8.03517643e-03 -5.61317336e-03\n",
      "  1.05687790e-02  3.26163764e-03 -3.91989760e-02 -9.38677341e-02\n",
      "  1.14227191e-01  6.57304525e-02 -4.72633801e-02  1.45087531e-02\n",
      " -3.54490243e-02 -3.37761790e-02 -5.15505821e-02 -3.81003087e-03\n",
      " -5.15036434e-02 -5.93429208e-02 -1.69413106e-03  7.42107555e-02\n",
      " -4.20091711e-02 -7.19974861e-02  3.17250341e-02 -1.66303609e-02\n",
      "  3.96981975e-03 -6.52750805e-02  2.77391206e-02 -7.51648843e-02\n",
      "  2.27455813e-02 -3.91368233e-02  1.54315708e-02 -5.54908253e-02\n",
      "  1.23318778e-02 -2.59520840e-02  6.66423365e-02 -6.91257856e-34\n",
      "  3.31628993e-02  8.47928897e-02 -6.65583536e-02  3.33541483e-02\n",
      "  4.71610995e-03  1.35361906e-02 -5.38694225e-02  9.20693949e-02\n",
      " -2.96876524e-02  3.16219628e-02 -2.37497427e-02  1.98771134e-02\n",
      "  1.03446193e-01 -9.06947330e-02  6.30627805e-03  1.42886378e-02\n",
      "  1.19294031e-02  6.43725600e-03  4.20104451e-02  1.25344852e-02\n",
      "  3.93019095e-02  5.35691939e-02 -4.30749543e-02  6.10432737e-02\n",
      " -5.39755638e-05  6.91682324e-02  1.05520273e-02  1.22111822e-02\n",
      " -7.23185241e-02  2.50469409e-02 -5.18371090e-02 -4.36562337e-02\n",
      " -6.71818480e-02  1.34828305e-02 -7.25888759e-02  7.04170577e-03\n",
      "  6.58939555e-02  1.08994525e-02 -2.60010525e-03  5.49968779e-02\n",
      "  5.06966673e-02  3.27948667e-02 -6.68833256e-02  6.45557418e-02\n",
      " -2.52075978e-02 -2.92572267e-02 -1.16696708e-01  3.24064381e-02\n",
      "  5.85858189e-02 -3.51756513e-02 -7.15240464e-02  2.24935990e-02\n",
      " -1.00786708e-01 -4.74545062e-02 -7.61962458e-02 -5.87166660e-02\n",
      "  4.21138369e-02 -7.47213811e-02  1.98468119e-02 -3.36501864e-03\n",
      " -5.29736467e-02  2.74729729e-02  3.45736556e-02 -6.11846708e-02\n",
      "  1.06364816e-01 -9.64120179e-02 -4.55944538e-02  1.51489722e-02\n",
      " -5.13525493e-03 -6.64447621e-02  4.31721136e-02 -1.10405860e-02\n",
      " -9.80251096e-03  7.53783211e-02 -1.49571076e-02 -4.80208397e-02\n",
      "  5.80726378e-02 -2.43896488e-02 -2.23137699e-02 -4.36992310e-02\n",
      "  5.12053818e-02 -3.28625962e-02  1.08763270e-01  6.08926602e-02\n",
      "  3.30794253e-03  5.53819798e-02  8.43201056e-02  1.27087412e-02\n",
      "  3.84465642e-02  6.52325526e-02 -2.94683911e-02  5.08005098e-02\n",
      " -2.09347792e-02  1.46135688e-01  2.25561298e-02 -1.77227744e-08\n",
      " -5.02672642e-02 -2.79223896e-04 -1.00328632e-01  2.42811684e-02\n",
      " -7.54043311e-02 -3.79140042e-02  3.96049358e-02  3.10079660e-02\n",
      " -9.05703101e-03 -6.50411695e-02  4.05452959e-02  4.83390428e-02\n",
      " -4.56962548e-02  4.76006744e-03  2.64360895e-03  9.35613960e-02\n",
      " -4.02599834e-02  3.27401944e-02  1.18298084e-02  5.54344803e-02\n",
      "  1.48052245e-01  7.21189231e-02  2.76976527e-04  1.68651044e-02\n",
      "  8.34881421e-03 -8.76154006e-03 -1.33649232e-02  6.14236854e-02\n",
      "  1.57168079e-02  6.94961101e-02  1.08621791e-02  6.08018078e-02\n",
      " -5.33421896e-02 -3.47923934e-02 -3.36272009e-02  6.93906397e-02\n",
      "  1.22987516e-02 -1.45237371e-01 -2.06971425e-03 -4.61132377e-02\n",
      "  3.72748077e-03 -5.59354573e-03 -1.00659825e-01 -4.45953049e-02\n",
      "  5.40921316e-02  4.98891203e-03  1.49534605e-02 -8.26059729e-02\n",
      "  6.26630709e-02 -5.01908641e-03 -4.81857918e-02 -3.53991129e-02\n",
      "  9.03391931e-03 -2.42338069e-02  5.66267446e-02  2.51529086e-02\n",
      " -1.70708634e-02 -1.24780433e-02  3.19518149e-02  1.38420891e-02\n",
      " -1.55814970e-02  1.00178219e-01  1.23657145e-01 -4.22967188e-02]\n",
      "\n",
      "Sentence: Sentences are passed as a list of string.\n",
      "Embedding: [ 5.64524867e-02  5.50024137e-02  3.13796178e-02  3.39484848e-02\n",
      " -3.54247205e-02  8.34668130e-02  9.88800526e-02  7.27545423e-03\n",
      " -6.68657245e-03 -7.65810162e-03  7.93738589e-02  7.39659299e-04\n",
      "  1.49291912e-02 -1.51046989e-02  3.67674232e-02  4.78743240e-02\n",
      " -4.81969379e-02 -3.76052186e-02 -4.60278541e-02 -8.89816210e-02\n",
      "  1.20228112e-01  1.30663201e-01 -3.73935848e-02  2.47858511e-03\n",
      "  2.55823275e-03  7.25814402e-02 -6.80436417e-02 -5.24696186e-02\n",
      "  4.90234159e-02  2.99563222e-02 -5.84429875e-02 -2.02263128e-02\n",
      "  2.08821762e-02  9.76691991e-02  3.52390334e-02  3.91140804e-02\n",
      "  1.05667925e-02  1.56234240e-03 -1.30822808e-02  8.52902699e-03\n",
      " -4.84096119e-03 -2.03766357e-02 -2.71800589e-02  2.83307601e-02\n",
      "  3.66017818e-02  2.51276121e-02 -9.90862250e-02  1.15626454e-02\n",
      " -3.60380076e-02 -7.23783895e-02 -1.12670124e-01  1.12942280e-02\n",
      " -3.86397354e-02  4.67386432e-02 -2.88460311e-02  2.26703733e-02\n",
      " -8.52407143e-03  3.32815088e-02 -1.06580707e-03 -7.09745735e-02\n",
      " -6.31169975e-02 -5.72187006e-02 -6.16026558e-02  5.47146387e-02\n",
      "  1.18317800e-02 -4.66260649e-02  2.56960038e-02 -7.07412418e-03\n",
      " -5.73842861e-02  4.12839465e-02 -5.91503493e-02  5.89021668e-02\n",
      " -4.41697687e-02  4.65081520e-02 -3.15814614e-02  5.58312833e-02\n",
      "  5.54578044e-02 -5.96533604e-02  4.06407416e-02  4.83763404e-03\n",
      " -4.96768169e-02 -1.00944348e-01  3.40078399e-02  4.13270667e-03\n",
      " -2.93524563e-03  2.11837552e-02 -3.73962335e-02 -2.79067159e-02\n",
      " -4.61767651e-02  5.26138544e-02 -2.79734693e-02 -1.62379280e-01\n",
      "  6.61042407e-02  1.72274169e-02 -5.45112230e-03  4.74473760e-02\n",
      " -3.82237621e-02 -3.96896899e-02  1.34545015e-02  4.49654274e-02\n",
      "  4.53674700e-03  2.82978714e-02  8.36633369e-02 -1.00858333e-02\n",
      " -1.19353965e-01 -3.84623967e-02  4.82858643e-02 -9.46083590e-02\n",
      "  1.91854313e-02 -9.96518210e-02 -6.30596727e-02  3.02696135e-02\n",
      "  1.17403017e-02 -4.78372015e-02 -6.20267540e-03 -3.32850367e-02\n",
      " -4.04386269e-03  1.28307352e-02  4.05254439e-02  7.56476671e-02\n",
      "  2.92434637e-02  2.84270439e-02 -2.78939027e-02  1.66858174e-02\n",
      " -2.47961562e-02 -6.83651194e-02  2.89968941e-02 -5.39867748e-33\n",
      " -2.69011525e-03 -2.65069176e-02 -6.47927693e-04 -8.46193731e-03\n",
      " -7.35154673e-02  4.94083436e-03 -5.97842187e-02  1.03438264e-02\n",
      "  2.12905253e-03 -2.88218958e-03 -3.17076668e-02 -9.42364410e-02\n",
      "  3.03019807e-02  7.00226501e-02  4.50685620e-02  3.69438976e-02\n",
      "  1.13593582e-02  3.53027023e-02  5.50450850e-03  1.34415983e-03\n",
      "  3.46121937e-03  7.75047466e-02  5.45112677e-02 -7.92056397e-02\n",
      " -9.31696743e-02 -4.03398685e-02  3.10668852e-02 -3.83081473e-02\n",
      " -5.89443371e-02  1.93331819e-02 -2.67159846e-02 -7.91938156e-02\n",
      "  1.04186758e-04  7.70621449e-02  4.16603386e-02  8.90932307e-02\n",
      "  3.56843397e-02 -1.09153055e-02  3.71498615e-02 -2.07070690e-02\n",
      " -2.46100929e-02 -2.05025040e-02  2.62201317e-02  3.43590342e-02\n",
      "  4.39250879e-02 -8.20519589e-03 -8.40710402e-02  4.24170531e-02\n",
      "  4.87499312e-02  5.95384575e-02  2.87747663e-02  3.37638333e-02\n",
      " -4.07442637e-02 -1.66372745e-03  7.91927949e-02  3.41088437e-02\n",
      " -5.72836900e-04  1.87749565e-02 -1.36963855e-02  7.38332868e-02\n",
      "  5.74510836e-04  8.33505094e-02  5.60810715e-02 -1.13711152e-02\n",
      "  4.42611389e-02  2.69581899e-02 -4.80535962e-02 -3.15087326e-02\n",
      "  7.75226429e-02  1.81773007e-02 -8.83005559e-02 -7.85518717e-03\n",
      " -6.22243248e-02  7.19372928e-02 -2.33475007e-02  6.52481429e-03\n",
      " -9.49527975e-03 -9.88312960e-02  4.01306301e-02  3.07397172e-02\n",
      " -2.21607368e-02 -9.45911556e-02  1.02368193e-02  1.02187760e-01\n",
      " -4.12960015e-02 -3.15778144e-02  4.74752411e-02 -1.10209778e-01\n",
      "  1.69614796e-02 -3.71709093e-02 -1.03261573e-02 -4.72538210e-02\n",
      " -1.20213879e-02 -1.93255227e-02  5.79292551e-02  4.23866365e-34\n",
      "  3.92012782e-02  8.41361359e-02 -1.02946706e-01  6.92259893e-02\n",
      "  1.68821365e-02 -3.26760747e-02  9.65957530e-03  1.80899594e-02\n",
      "  2.17939839e-02  1.63189247e-02 -9.69292298e-02  3.74851399e-03\n",
      " -2.38456707e-02 -3.44056077e-02  7.11962804e-02  9.21933330e-04\n",
      " -6.23857602e-03  3.23754437e-02 -8.90360330e-04  5.01907384e-03\n",
      " -4.24537957e-02  9.89084020e-02 -4.60321195e-02  4.69704792e-02\n",
      " -1.75284483e-02 -7.02516502e-03  1.32743763e-02 -5.30151874e-02\n",
      "  2.66403705e-03  1.45818805e-02  7.43346941e-03 -3.07131689e-02\n",
      " -2.09416542e-02  8.24109912e-02 -5.15893847e-02 -2.71178316e-02\n",
      "  1.17582999e-01  7.72504183e-03 -1.89523306e-02  3.94559689e-02\n",
      "  7.17360526e-02  2.59116702e-02  2.75191534e-02  9.50541813e-03\n",
      " -3.02355289e-02 -4.07944322e-02 -1.04028486e-01 -7.97425397e-03\n",
      " -3.64458049e-03  3.29716764e-02 -2.35954970e-02 -7.50514399e-03\n",
      " -5.82234114e-02 -3.17906328e-02 -4.18049209e-02  2.17453577e-02\n",
      " -6.67291731e-02 -4.89104502e-02  4.58513293e-03 -2.66046487e-02\n",
      " -1.12597041e-01  5.11167683e-02  5.48534170e-02 -6.69857338e-02\n",
      "  1.26766324e-01 -8.59487429e-02 -5.94231449e-02 -2.92185857e-03\n",
      " -1.14875669e-02 -1.26025781e-01 -3.48277879e-03 -9.12001953e-02\n",
      " -1.22933045e-01  1.33777354e-02 -4.75774780e-02 -6.57933280e-02\n",
      " -3.39409932e-02 -3.07107400e-02 -5.22034168e-02 -2.35463995e-02\n",
      "  5.90035170e-02 -3.85757610e-02  3.19701210e-02  4.05118950e-02\n",
      "  1.67077594e-02 -3.58280949e-02  1.45688243e-02  3.20137665e-02\n",
      " -1.34843700e-02  6.07819706e-02 -8.31401907e-03 -1.08105978e-02\n",
      "  4.69410568e-02  7.66133890e-02 -4.23400141e-02 -2.11963300e-08\n",
      " -7.25292489e-02 -4.20227870e-02 -6.12374805e-02  5.24666682e-02\n",
      " -1.42363878e-02  1.18487151e-02 -1.40789226e-02 -3.67529914e-02\n",
      " -4.44978140e-02 -1.15140509e-02  5.23316860e-02  2.96652280e-02\n",
      " -4.62780595e-02 -3.70892473e-02  1.89129263e-02  2.04307027e-02\n",
      " -2.24006362e-02 -1.48562696e-02 -1.79504398e-02  4.20007557e-02\n",
      "  1.40942959e-02 -2.83492170e-02 -1.16862990e-01  1.48956645e-02\n",
      " -7.30577565e-04  5.66028357e-02 -2.68740021e-02  1.09106667e-01\n",
      "  2.94563570e-03  1.19267896e-01  1.14212461e-01  8.92973617e-02\n",
      " -1.70255378e-02 -4.99054156e-02 -2.11930685e-02  3.18421610e-02\n",
      "  7.03436211e-02 -1.02929436e-01  8.23816881e-02  2.81967912e-02\n",
      "  3.21146473e-02  3.79108079e-02 -1.09553099e-01  8.19620267e-02\n",
      "  8.73216465e-02 -5.73563986e-02 -2.01709121e-02 -5.69444187e-02\n",
      " -1.30338753e-02 -5.55684343e-02 -1.32966377e-02  8.64010397e-03\n",
      "  5.30012436e-02 -4.06847000e-02  2.71709189e-02 -2.55949632e-03\n",
      "  3.05775702e-02 -4.61865254e-02  4.68032714e-03 -3.64947096e-02\n",
      "  6.80803061e-02  6.65087700e-02  8.49151909e-02 -3.32849212e-02]\n",
      "\n",
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: [ 4.39335555e-02  5.89344241e-02  4.81783748e-02  7.75481015e-02\n",
      "  2.67443880e-02 -3.76295708e-02 -2.60511227e-03 -5.99430539e-02\n",
      " -2.49602785e-03  2.20728423e-02  4.80258949e-02  5.57553247e-02\n",
      " -3.89454402e-02 -2.66168062e-02  7.69344904e-03 -2.62376498e-02\n",
      " -3.64160836e-02 -3.78161259e-02  7.40781352e-02 -4.95050587e-02\n",
      " -5.85216992e-02 -6.36196733e-02  3.24349962e-02  2.20085531e-02\n",
      " -7.10637420e-02 -3.31577957e-02 -6.94103912e-02 -5.00374287e-02\n",
      "  7.46267885e-02 -1.11133814e-01 -1.23063233e-02  3.77456397e-02\n",
      " -2.80313473e-02  1.45353414e-02 -3.15585434e-02 -8.05836320e-02\n",
      "  5.83525896e-02  2.59002740e-03  3.92802097e-02  2.57695783e-02\n",
      "  4.98506166e-02 -1.75621535e-03 -4.55298088e-02  2.92607900e-02\n",
      " -1.02017283e-01  5.22287451e-02 -7.90899843e-02 -1.02857500e-02\n",
      "  9.20248125e-03  1.30732246e-02 -4.04777899e-02 -2.77925003e-02\n",
      "  1.24667892e-02  6.72833025e-02  6.81247637e-02 -7.57117104e-03\n",
      " -6.09940616e-03 -4.23777364e-02  5.17815836e-02 -1.56707745e-02\n",
      "  9.56360158e-03  4.12390493e-02  2.14959271e-02  1.04293339e-02\n",
      "  2.73349416e-02  1.87062453e-02 -2.69607287e-02 -7.00541884e-02\n",
      " -1.04700483e-01 -1.89873227e-03  1.77016407e-02 -5.74725680e-02\n",
      " -1.44223468e-02  4.70475119e-04  2.33231811e-03 -2.51920484e-02\n",
      "  4.93003950e-02 -5.09609878e-02  6.31983131e-02  1.49164917e-02\n",
      " -2.70767100e-02 -4.52875271e-02 -4.90594208e-02  3.74940410e-02\n",
      "  3.84580344e-02  1.56904291e-03  3.09922509e-02  2.01630723e-02\n",
      " -1.24363489e-02 -3.06720212e-02 -2.78819185e-02 -6.89182431e-02\n",
      " -5.13677374e-02  2.14795675e-02  1.15747135e-02  1.25412666e-03\n",
      "  1.88765507e-02 -4.42318730e-02 -4.49817255e-02 -3.41874245e-03\n",
      "  1.31131383e-02  2.00099293e-02  1.21099748e-01  2.31074542e-02\n",
      " -2.20159665e-02 -3.28846686e-02 -3.15514393e-03  1.17877717e-04\n",
      "  9.91498679e-02  1.65239293e-02 -4.69671609e-03 -1.45366834e-02\n",
      " -3.71077168e-03  9.65136215e-02  2.85908319e-02  2.13481858e-02\n",
      " -7.17645362e-02 -2.41142046e-02 -4.40940820e-02 -1.07346885e-01\n",
      "  6.79946020e-02  1.30466729e-01 -7.97029734e-02  6.79508084e-03\n",
      " -2.37511713e-02 -4.61636595e-02 -2.99650989e-02 -3.69409936e-33\n",
      "  7.30969682e-02 -2.20171604e-02 -8.61464590e-02 -7.14379698e-02\n",
      " -6.36742190e-02 -7.21863359e-02 -5.93041815e-03 -2.33641230e-02\n",
      " -2.83658095e-02  4.77434807e-02 -8.06175992e-02 -1.56474777e-03\n",
      "  1.38443932e-02 -2.86236294e-02 -3.35386507e-02 -1.13777533e-01\n",
      " -9.17634554e-03 -1.08101377e-02  3.23196203e-02  5.88380769e-02\n",
      "  3.34208459e-02  1.07987933e-01 -3.72713096e-02 -2.96770260e-02\n",
      "  5.17190285e-02 -2.25338805e-02 -6.96090832e-02 -2.14475188e-02\n",
      " -2.33411100e-02  4.82199825e-02 -3.58766355e-02 -4.68991511e-02\n",
      " -3.97873707e-02  1.10813260e-01 -1.43007115e-02 -1.18464500e-01\n",
      "  5.82915209e-02 -6.25889227e-02 -2.94041280e-02  6.03238456e-02\n",
      " -2.44411780e-03  1.60115696e-02  2.67233942e-02  2.49530766e-02\n",
      " -6.49318621e-02 -1.06801530e-02  2.81465128e-02  1.03564002e-02\n",
      " -6.63578568e-04  1.98186152e-02 -3.04288473e-02  6.28419407e-03\n",
      "  5.15268035e-02 -4.75375280e-02 -6.44421354e-02  9.55031663e-02\n",
      "  7.55858123e-02 -2.81574745e-02 -3.49965878e-02  1.01816364e-01\n",
      "  1.98732410e-02 -3.68036702e-02  2.93526566e-03 -5.00745289e-02\n",
      "  1.50932163e-01 -6.16079532e-02 -8.58812854e-02  7.13989139e-03\n",
      " -1.33065674e-02  7.80405253e-02  1.75250899e-02  4.21279781e-02\n",
      "  3.57939303e-02 -1.32950380e-01  3.56970429e-02 -2.03116965e-02\n",
      "  1.24910194e-02 -3.80355157e-02  4.91543338e-02 -1.56540647e-02\n",
      "  1.21418267e-01 -8.08644518e-02 -4.68782112e-02  4.10843156e-02\n",
      " -1.84318144e-02  6.69690743e-02  4.33594873e-03  2.27315798e-02\n",
      " -1.36428867e-02 -4.53238264e-02 -3.92829180e-02 -6.29887776e-03\n",
      "  5.29610179e-02 -3.69064547e-02  7.11677000e-02  2.33343306e-33\n",
      "  1.05231345e-01 -4.81874458e-02  6.95919171e-02  6.56976029e-02\n",
      " -4.65149134e-02  5.14492393e-02 -1.24475202e-02  3.20872031e-02\n",
      " -9.23356563e-02  5.00932820e-02 -3.28876227e-02  1.39138885e-02\n",
      " -8.70246033e-04 -4.90907906e-03  1.03946365e-01  3.21582746e-04\n",
      "  5.28110415e-02 -1.17990654e-02  2.31565628e-02  1.31768323e-02\n",
      " -5.25962710e-02  3.26702632e-02  3.08708113e-04  6.41128942e-02\n",
      "  3.88501063e-02  5.88008389e-02  8.29793140e-02 -1.88149605e-02\n",
      " -2.26377267e-02 -1.00473680e-01 -3.83752435e-02 -5.88081405e-02\n",
      "  1.82420271e-03 -4.26994711e-02  2.50195358e-02  6.40059710e-02\n",
      " -3.77482846e-02 -6.83903368e-03 -2.54603243e-03 -9.76043120e-02\n",
      "  1.88475382e-02 -8.83174012e-04  1.73611771e-02  7.10790604e-02\n",
      "  3.30393389e-02  6.93418179e-03 -5.60523532e-02  5.14634661e-02\n",
      " -4.29542027e-02  4.60077301e-02 -8.78832396e-03  3.17289121e-02\n",
      "  4.93965670e-02  2.95190178e-02 -5.05192839e-02 -5.43186776e-02\n",
      "  1.49970918e-04 -2.76614614e-02  3.46879102e-02 -2.10890137e-02\n",
      "  1.38060246e-02  2.99886893e-02  1.39744664e-02 -4.26471420e-03\n",
      " -1.50337238e-02 -8.76095816e-02 -6.85053617e-02 -4.28141579e-02\n",
      "  7.76944906e-02 -7.10285306e-02 -7.37689110e-03  2.13726759e-02\n",
      "  1.35562653e-02 -7.90464506e-02  5.47662005e-03  8.30663368e-02\n",
      "  1.14148036e-01  1.80760049e-03  8.75491127e-02 -4.16045040e-02\n",
      "  1.55416336e-02 -1.01206284e-02 -7.32440269e-03  1.07966410e-02\n",
      " -6.62816986e-02  3.98414023e-02 -1.16711564e-01  6.42993823e-02\n",
      "  4.02920097e-02 -6.54741451e-02  1.95052531e-02  8.09995681e-02\n",
      "  5.36463968e-02  7.67969787e-02 -1.34852454e-02 -1.76919031e-08\n",
      " -4.43935134e-02  9.20642540e-03 -8.79590437e-02  4.26921621e-02\n",
      "  7.31364936e-02  1.68427341e-02 -4.03263196e-02  1.85131300e-02\n",
      "  8.44172463e-02 -3.74476872e-02  3.02996244e-02  2.90641598e-02\n",
      "  6.36878982e-02  2.89750397e-02 -1.47270095e-02  1.77543219e-02\n",
      " -3.36895548e-02  1.73161123e-02  3.37875448e-02  1.76826075e-01\n",
      " -1.75533462e-02 -6.03078008e-02 -1.43394722e-02 -2.38536522e-02\n",
      " -4.45531234e-02 -2.89850403e-02 -8.96776468e-02 -1.75940362e-03\n",
      " -2.61486210e-02  5.93998982e-03 -5.18355593e-02  8.57279673e-02\n",
      " -8.18398520e-02  8.35440308e-03  4.00789976e-02  4.17763926e-02\n",
      "  1.04573570e-01 -2.86566350e-03  1.96691398e-02  5.81047777e-03\n",
      "  1.33253494e-02  4.51001376e-02 -2.17588134e-02 -1.39493067e-02\n",
      " -6.86992332e-02 -2.94118072e-03 -3.10764946e-02 -1.05854452e-01\n",
      "  6.91624358e-02 -4.24114801e-02 -4.67682183e-02 -3.64750884e-02\n",
      "  4.50399779e-02  6.09816425e-02 -6.56561852e-02 -5.45641175e-03\n",
      " -1.86226759e-02 -6.31484911e-02 -3.87436710e-02  3.46733853e-02\n",
      "  5.55458292e-02  5.21628037e-02  5.61064929e-02  1.02063946e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "# Sentences are encoded by calling bert_vect.encode()\n",
    "embeddings = bert_vect.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "427fadd0-85fc-462b-a2d0-5a56f6abc2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 384)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa9ec195-32e2-486c-ab28-2fec01afff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity between 1 and 2: tensor([[0.4914]])\n",
      "Cosine-Similarity between 1 and 3: tensor([[0.1904]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "emb1 = bert_vect.encode(\"I am eating Mango\")\n",
    "emb2 = bert_vect.encode(\"I like fruits\")\n",
    "emb3 = bert_vect.encode(\"I work at Microsoft\")\n",
    "cos_sim_12 = util.cos_sim(emb1, emb2)\n",
    "cos_sim_13 = util.cos_sim(emb1, emb3)\n",
    "print(\"Cosine-Similarity between 1 and 2:\", cos_sim_12)\n",
    "print(\"Cosine-Similarity between 1 and 3:\", cos_sim_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0636c991-3f32-42d7-8151-bc08f11354a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.7553, -0.1050,  0.2474, -0.0704, -0.0333,  0.1707,  0.0476,\n",
       "          0.0630],\n",
       "        [ 0.7553,  1.0000, -0.0610,  0.1442, -0.0809, -0.0216,  0.1157,  0.0362,\n",
       "          0.0216],\n",
       "        [-0.1050, -0.0610,  1.0000, -0.1088,  0.0217, -0.0413, -0.0928,  0.0231,\n",
       "          0.0247],\n",
       "        [ 0.2474,  0.1442, -0.1088,  1.0000, -0.0348,  0.0362,  0.7369,  0.0821,\n",
       "          0.1389],\n",
       "        [-0.0704, -0.0809,  0.0217, -0.0348,  1.0000, -0.1654, -0.0592,  0.1961,\n",
       "          0.2564],\n",
       "        [-0.0333, -0.0216, -0.0413,  0.0362, -0.1654,  1.0000,  0.0769, -0.0380,\n",
       "         -0.0895],\n",
       "        [ 0.1707,  0.1157, -0.0928,  0.7369, -0.0592,  0.0769,  1.0000,  0.0495,\n",
       "          0.1191],\n",
       "        [ 0.0476,  0.0362,  0.0231,  0.0821,  0.1961, -0.0380,  0.0495,  1.0000,\n",
       "          0.6433],\n",
       "        [ 0.0630,  0.0216,  0.0247,  0.1389,  0.2564, -0.0895,  0.1191,  0.6433,\n",
       "          1.0000]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = bert_vect.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "691d3793-878d-4c93-b7be-156524b5fd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>w2v_doc_embeddings</th>\n",
       "      <th>glove_doc_embeddings</th>\n",
       "      <th>sbert_doc_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "      <td>best time</td>\n",
       "      <td>[best, time]</td>\n",
       "      <td>[-0.008673585, 0.00289795, 0.0021581696, -0.00...</td>\n",
       "      <td>[0.432825, 0.1588, 0.39231, -0.493835, 0.00431...</td>\n",
       "      <td>[-0.0924282, 0.032537505, -0.018796407, -0.033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of times.</td>\n",
       "      <td>worst time</td>\n",
       "      <td>[worst, time]</td>\n",
       "      <td>[-0.007879351, 0.0024533845, -0.0009934164, 0....</td>\n",
       "      <td>[0.73222, 0.23221499, 0.29085773, -0.31792, -0...</td>\n",
       "      <td>[-0.073623896, 0.07536217, 0.005589636, 0.0316...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>[age, wisdom]</td>\n",
       "      <td>[-0.0043894527, 0.004767893, 0.0024528443, 0.0...</td>\n",
       "      <td>[-0.045359, -0.66945, -0.33981, 0.167995, 0.70...</td>\n",
       "      <td>[0.02470788, 0.14167035, 0.012471464, 0.063883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE age of foolishness</td>\n",
       "      <td>age foolishness</td>\n",
       "      <td>[age, foolishness]</td>\n",
       "      <td>[-0.00022083164, 0.0016568756, -0.0008546477, ...</td>\n",
       "      <td>[0.14098799, 0.16774501, -0.592085, 0.2619315,...</td>\n",
       "      <td>[0.05471872, 0.13996215, 0.05851771, -0.003388...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text       clean_text tokenised_sentences  \\\n",
       "0     it Was the best oF Times $        best time        [best, time]   \n",
       "1     It was The worst of times.       worst time       [worst, time]   \n",
       "2     IT 9 was tHe age Of wisdom       age wisdom       [age, wisdom]   \n",
       "3  it was thE age of foolishness  age foolishness  [age, foolishness]   \n",
       "\n",
       "                                  w2v_doc_embeddings  \\\n",
       "0  [-0.008673585, 0.00289795, 0.0021581696, -0.00...   \n",
       "1  [-0.007879351, 0.0024533845, -0.0009934164, 0....   \n",
       "2  [-0.0043894527, 0.004767893, 0.0024528443, 0.0...   \n",
       "3  [-0.00022083164, 0.0016568756, -0.0008546477, ...   \n",
       "\n",
       "                                glove_doc_embeddings  \\\n",
       "0  [0.432825, 0.1588, 0.39231, -0.493835, 0.00431...   \n",
       "1  [0.73222, 0.23221499, 0.29085773, -0.31792, -0...   \n",
       "2  [-0.045359, -0.66945, -0.33981, 0.167995, 0.70...   \n",
       "3  [0.14098799, 0.16774501, -0.592085, 0.2619315,...   \n",
       "\n",
       "                                sbert_doc_embeddings  \n",
       "0  [-0.0924282, 0.032537505, -0.018796407, -0.033...  \n",
       "1  [-0.073623896, 0.07536217, 0.005589636, 0.0316...  \n",
       "2  [0.02470788, 0.14167035, 0.012471464, 0.063883...  \n",
       "3  [0.05471872, 0.13996215, 0.05851771, -0.003388...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sbert_doc_embeddings'] = df['clean_text'].apply(bert_vect.encode)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
